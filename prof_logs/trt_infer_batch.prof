Timer unit: 1e-06 s

Total time: 15.708 s
File: trt_infer_batch.py
Function: get_features at line 168

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   168                                               @profile
   169                                               def get_features(self, json_file, wav_path=None):
   170         2    1989607.0 994803.5     12.7          eval_data_layer = nemo_asr.AudioToTextDataLayer(
   171         1          1.0      1.0      0.0              manifest_filepath=json_file,
   172         1          1.0      1.0      0.0              labels=self.vocab,
   173         1          1.0      1.0      0.0              batch_size=64,
   174         1          1.0      1.0      0.0              sample_rate=self.sample_rate,
   175         1          1.0      1.0      0.0              shuffle=False
   176                                                   )
   177         1        984.0    984.0      0.0          audio_signal_e1, a_sig_length_e1, transcript_e1, transcript_len_e1 = eval_data_layer()
   178         2        654.0    327.0      0.0          processed_signal_e1, p_length_e1 = self.data_preprocessor(
   179         1          1.0      1.0      0.0              input_signal=audio_signal_e1, length=a_sig_length_e1)
   180         3   12635640.0 4211880.0     80.4          feature_tensors = self.neural_factory.infer(
   181         2          7.0      3.5      0.0              tensors=[processed_signal_e1])[0]
   182                                                   
   183       113        163.0      1.4      0.0          for i in range(len(feature_tensors)):
   184       112     174308.0   1556.3      1.1              tmp_tensor = torch.zeros((feature_tensors[i].shape[0], 64, 1600))
   185       112     543285.0   4850.8      3.5              tmp_tensor[:, :, :feature_tensors[i].shape[2]] += feature_tensors[i]
   186       112        907.0      8.1      0.0              feature_tensors[i] = tmp_tensor
   187         1     362432.0 362432.0      2.3          feature_tensors = torch.cat(feature_tensors, dim=0)
   188         1          3.0      3.0      0.0          return feature_tensors

Total time: 43.8316 s
File: trt_infer_batch.py
Function: trt_infer at line 191

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   191                                           @profile
   192                                           def trt_infer(trt_path, feature_tensors, batch_size=64):
   193         1        102.0    102.0      0.0      stream = cuda.Stream()
   194         1         68.0     68.0      0.0      f = open(trt_path, "rb") 
   195         1   14414123.0 14414123.0     32.9      runtime = trt.Runtime(TRT_LOGGER) 
   196         1     361231.0 361231.0      0.8      trt_engine = runtime.deserialize_cuda_engine(f.read())
   197         1       5478.0   5478.0      0.0      trt_ctx = trt_engine.create_execution_context() # 创建context用来执行推断
   198                                               
   199         1         65.0     65.0      0.0      profile_shape = trt_engine.get_profile_shape(profile_index=0, binding=0)
   200         1          4.0      4.0      0.0      max_input_shape = profile_shape[2]
   201         1          3.0      3.0      0.0      max_output_shape = [
   202         1         14.0     14.0      0.0              max_input_shape[0], vocabulary_size,
   203         1          3.0      3.0      0.0              (max_input_shape[-1] + 1) // 2
   204                                                   ]
   205         1        106.0    106.0      0.0      output_nbytes = trt.volume(max_output_shape) * trt.float32.itemsize
   206         1        234.0    234.0      0.0      d_output = cuda.mem_alloc(output_nbytes)
   207                                           
   208         1          2.0      2.0      0.0      predictions = []
   209       113        370.0      3.3      0.0      for step in range(feature_tensors.shape[0] // batch_size + 1):
   210       112        488.0      4.4      0.0          if (step+1)*batch_size < feature_tensors.shape[0]:
   211       111       1860.0     16.8      0.0              input_features = feature_tensors[step*batch_size:(step+1)*batch_size]
   212                                                   else:
   213         1         16.0     16.0      0.0              input_features = feature_tensors[step*batch_size:]
   214                                           
   215       112       4952.0     44.2      0.0          input_nbytes = trt.volume(input_features.shape) * trt.float32.itemsize
   216       112     843972.0   7535.5      1.9          d_input = cuda.mem_alloc(input_nbytes)
   217                                           
   218       112       5415.0     48.3      0.0          trt_ctx.set_binding_shape(0, input_features.shape)
   219       112        644.0      5.8      0.0          assert trt_ctx.all_binding_shapes_specified
   220                                           
   221       224     775413.0   3461.7      1.8          h_output = cuda.pagelocked_empty(tuple(trt_ctx.get_binding_shape(1)),
   222       112        537.0      4.8      0.0                                          dtype=np.float32)
   223                                           
   224       224     813169.0   3630.2      1.9          h_input_signal = cuda.register_host_memory(
   225       112       9665.0     86.3      0.0              np.ascontiguousarray(input_features.ravel()))
   226       112       4617.0     41.2      0.0          cuda.memcpy_htod_async(d_input, h_input_signal, stream)
   227       336     315379.0    938.6      0.7          trt_ctx.execute_async_v2(bindings=[int(d_input),
   228       112        212.0      1.9      0.0                                          int(d_output)],
   229       112        332.0      3.0      0.0                                  stream_handle=stream.handle)
   230       112       2726.0     24.3      0.0          cuda.memcpy_dtoh_async(h_output, d_output, stream)
   231       112   18233839.0 162802.1     41.6          stream.synchronize()
   232                                           
   233       112    1656053.0  14786.2      3.8          predictions += torch.tensor(h_output).argmax(dim=-1, keepdim=False)
   234                                               
   235         1      80370.0  80370.0      0.2      predictions = torch.stack(predictions)
   236         1    6300118.0 6300118.0     14.4      hypotheses = ctc_decoder.post_process_predictions([predictions], vocab)
   237         1          5.0      5.0      0.0      return hypotheses

Total time: 63.0534 s
File: trt_infer_batch.py
Function: main at line 242

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   242                                           @profile
   243                                           def main():
   244         1          4.0      4.0      0.0      onnx_path = sys.argv[1]
   245         1          2.0      2.0      0.0      mode = 'fp16'
   246         1         22.0     22.0      0.0      trt_path = build_trt_engine(onnx_path, mode)
   247         1          1.0      1.0      0.0      model_args = [
   248         1          1.0      1.0      0.0          '--model_config', 'examples/asr/configs/quartznet15x5.yaml',
   249         1          1.0      1.0      0.0          '--load_dir', 'model/english/',
   250         1          1.0      1.0      0.0          '--lm_path', './language-model/english_4gram_1.2.binary',
   251         1          1.0      1.0      0.0          '--eval_batch_size', '1',
   252         1          0.0      0.0      0.0          '--beam_width', '64',
   253         1          1.0      1.0      0.0          '--amp_opt_level', 'O1'
   254                                               ]
   255         1       1859.0   1859.0      0.0      parser = get_parser()
   256         1        836.0    836.0      0.0      args = parser.parse_args(model_args)
   257         1    3460491.0 3460491.0      5.5      asr_model = ModelASR(args)
   258                                               # trt_path = sys.argv[1]
   259         1          7.0      7.0      0.0      json_file = sys.argv[2]
   260         1          1.0      1.0      0.0      predict_file = sys.argv[3]
   261         1   15708765.0 15708765.0     24.9      feature_tensors = asr_model.get_features(json_file)
   262                                               # print(feature_tensors.shape)
   263                                               # print(feature_tensors)
   264         1   43842456.0 43842456.0     69.5      transcripts = trt_infer(trt_path, feature_tensors)
   265         1        260.0    260.0      0.0      with open(predict_file, 'w') as f:
   266      7128       7099.0      1.0      0.0          for transcript in transcripts:
   267      7127      31571.0      4.4      0.1              f.write(transcript + '\n')

